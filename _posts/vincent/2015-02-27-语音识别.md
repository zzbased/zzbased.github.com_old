---
layout: post
category : 机器学习
tagline: "Supporting tagline"
tags : [语音识别]
---
{% include JB/setup %}


最近，组里新来了一个博士同学。他的博士专业是语音识别，正好跟我们分享了一下语义识别相关的知识点。老早前，我就看过DengLi在微软的文章，结合肖博的分享，正好可以把语音识别相关的东东，在脑子里串起来梳理下，特撰文如下。

## 语音识别

- [Deep Neural Networks for Acoustic Modeling in Speech Recognition](http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/38131.pdf)
- [RECENT ADVANCES IN DEEP LEARNING FOR SPEECH RESEARCH AT MICROSOFT](http://msr-waypoint.com/pubs/188864/ICASSP-2013-OverviewMSRDeepLearning.pdf)
- [Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition](http://research.microsoft.com/pubs/144412/dbn4lvcsr-transaslp.pdf)
- [Deep Speech: Scaling up end-to-end speech recognition](http://arxiv.org/pdf/1412.5567v2.pdf)
- [为什么 Deep Learning 最先在语音识别和图像处理领域取得突破？](http://www.zhihu.com/question/21815490)

  DL 适合处理感知, 而非逻辑；
  感知与逻辑的重要区别在于输入数据在输入空间中做连续变化还是离散变化；
  神经生物学上对人脑的逻辑还理解的不够, 对感知理解的好一些所以糙出了DL；

- [语音识别的技术原理是什么](http://www.zhihu.com/question/20398418)

  - 信号处理及特征提取模块。该模块的主要任务是从输入信号中提取特征，供声学模型处理。同时，它一般也包括了一些信号处理技术，以尽可能降低环境噪声、信道、说话人等因素对特征造成的影响。

    主要有：降噪和分帧。分帧就是把波形切开成一小段一小段，每小段称为一帧。分帧操作通常使用移动窗函数来实现，分帧之前还要做一些预加重等操作，帧与帧之间是有交叠的。

    分帧后，语音就变成了很多小段。这时需要对这些时域波形做波形变换，常见的一种变换方法是提取MFCC特征，把每一帧波形变成一个12维向量。MFCC的计算首先用FFT将时域信号转化成频域，之后对其对数能量谱用依照Mel刻度分布的三角滤波器组进行卷积，最后对各个滤波器的输出构成的向量进行离散余弦变换DCT，取前N个系数。

    通常的特征有：线性预测系数LPC，倒谱系数CEP，梅尔频率倒谱系数MFCC，感知线性预测PLP。

    经过该模块处理后，声音就成了一个12行（假设声学特征是12维）、N列的一个矩阵，称之为观察序列，这里N为总帧数。

  - 再介绍三个概念

    单词：英语中就是单词，汉语中是汉字。
    音素：单词的发音由音素构成。对英语，一种常用的音素集是卡内基梅隆大学的一套由39个音素构成的音素集，参见The CMU Pronouncing Dictionary‎。汉语一般直接用全部声母和韵母作为音素集，另外汉语识别还分有调无调。
    状态：比音素更细致的语音单位。通常一个音素由3个状态构成。

    接下来，语音识别是怎么工作的呢？
    第一步，把帧识别成状态（难点）。
    第二步，把状态组合成音素。
    第三步，把音素组合成单词。

    语音识别系统的模型通常由声学模型和语言模型两部分组成，分别对应于语音到音节概率的计算和音节到字概率的计算。

  - 统计声学模型。典型系统多采用基于一阶隐马尔科夫模型进行建模。

    如何把帧识别成状态，可以看某帧对应哪个状态的概率最大，那这帧就属于哪个状态，这叫做“最大似然”。
    声学模型，里面存了一大堆参数，通过这些参数，就可以知道帧和状态对应的概率。

    使用隐马尔可夫模型（Hidden Markov Model，HMM），第一步，构建一个状态网络。第二步，从状态网络中寻找与声音最匹配的路径。
    首先构造单词级网络，然后展开成音素网络，然后展开成状态网络。然后在状态网络中搜索一条最佳路径，这条路径和语音之间的概率（称之为累积概率）最大。搜索的算法是一种动态规划剪枝的算法，称之为Viterbi算法，用于寻找全局最优路径。

    这里所说的累积概率，由三部分构成，分别是：
    观察概率：每帧和每个状态对应的概率；
    转移概率：每个状态转移到自身或转移到下个状态的概率；
    语言概率：根据语言统计规律得到的概率；
    其中，前两种概率从声学模型中获取，最后一种概率从语言模型中获取。

  - 发音词典。发音词典包含系统所能处理的词汇集及其发音。发音词典实际提供了声学模型建模单元与语言模型建模单元间的映射。

  - 语言模型。语言模型对系统所针对的语言进行建模。理论上，包括正则语言，上下文无关文法在内的各种语言模型都可以作为语言模型，但目前各种系统普遍采用的还是基于统计的N元文法及其变体。

  - 解码器。解码器是语音识别系统的核心之一，其任务是对输入的信号，根据声学、语言模型及词典，寻找能够以最大概率输出该信号的词串。
