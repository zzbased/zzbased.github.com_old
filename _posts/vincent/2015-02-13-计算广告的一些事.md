---
layout: post
category : 广告算法
tagline: "Supporting tagline"
tags : [广告, ctr预估]
---
{% include JB/setup %}

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

## RTB

- [Real-Time Bidding](http://tutorial.computational-advertising.org/images/WSDM2015.pdf)

	除了有各类DSP竞价算法、SSP底价算法外，还加入了anti-fraud和广告期权交易的内容。另外也罗列了做互联网广告研究的公开数据集和开源工具。

- 在RTB广告出价过程中，两个重点因素是：
1. 广告展示的效益(点击率/转化率)；
2. 展示花销。
以这两项因素为输入，我们的框架能优化出最优的RTB出价策略。
论文[Optimal Real-Time Bidding for Display Advertising](http://www0.cs.ucl.ac.uk/staff/w.zhang/papers/ortb-kdd.pdf) 实验基于@品友互动 [RTB数据集](http://t.cn/RP3pPQO)

## 计算广告

### 关于广告的讨论：

广告一般是model based的方法，搜索rank一般是rule bases的方法，推荐通常也是广告那种玩法，不过我倾向于面向用户的产品应该rule based思路做。@梁斌penny

把推荐看成user和item的dyad，用该user过去行为预测ctr来评估推荐系统，可以用广告这一套。但推荐看重的所谓novelty，diversity等等无法体现了，一般而言推荐是一堆策略的合成，广告相对单一一些，是否用广告架构与否不重要，关键要看问题是怎么定义的。

看了Hector Molina在Recsys'14上提的Search/Recomm/Ads三合一观点，挺赞同。这三个问题共同点都是matching a context to a collection of info obj, 核心的模块是filtering/ranking/personalisation, 从理论的cleanness和架构统一性来都很赞，实际中最大难度是各个应用各有自身调优需求，不好协调。

最终的目标不一样，搜索求准，推荐求新，广告求财…还是很难统一的，当然，底层框架是可以共用的

三个很不一样，搜索是站在用户角度识别用户想要什么。推荐是站在平台角度看想要引导什么。广告是以局外人看广告主、平台、用户分别想要什么。

[code - A Scalable Response Prediction Platform For Online Advertising](https://github.com/izenecloud/laser/)

## Query分析

[Semantic Matching in Search](http://www.nowpublishers.com/articles/foundations-and-trends-in-information-retrieval/INR-035)

[面向语义搜索的文本、图像、视频信息的结构化处理](http://weibo.com/p/1001603782125668144212)

## CTR预估

### 特征处理
在pCtr/pCvr/relevance问题中，最基本的问题就是特征处理。

- [特征处理入门 by BreezeDeus](https://breezedeus.github.io/2014/11/15/breezedeus-feature-processing.html)
- [特征选择 by ubiwang](http://www.flickering.cn/ads/2014/08/转化率预估-4特征选择－简介/)
- [美团推荐团队-机器学习中的数据清洗与特征处理综述](http://tech.meituan.com/machinelearning-data-feature-process.html)
- [Kaggle高手们的特征工程技巧](http://t.cn/RPiYmQP)
- [幻灯:特征工程《Feature Engineering》by David Epstein](http://t.cn/RL4oMW2) pdf:http://t.cn/RL4oMWL

### 特征降维
主要特征降维方法有：聚类，PCA，hashing

下面看一下[特征hash法](https://breezedeus.github.io/2014/11/20/breezedeus-feature-hashing.html)

- 特征哈希法的目标是把原始的高维特征向量压缩成较低维特征向量，且尽量不损失原始特征的表达能力。
- 特征hash法可用于 多任务学习(multitask learning)
- 大数据机器学习专家John Langford总结了一下关于使用hashing trick来处理大数据的重要文章：http://t.cn/RzbMxm5 值得一看。
- CS 2750 Machine Learning -[Dimensionality reduction Feature selection](http://people.cs.pitt.edu/~milos/courses/cs2750-Spring04/lectures/class20.pdf)

- 参考文献：
	- Kilian Weinberger et al. Feature Hashing for Large Scale Multitask Learning,2010.  or Feature hashing for large scale multitask learning
	- Joshua Attenberg et al. Collaborative Email-Spam Filtering with the Hashing-Trick, 2009.
	- Alekh Agarwal, Oliveier Chapelle, Miroslav Dud ́ık, and John Langford. A Reliable Effective Terascale Linear Learning System. Journal of Machine Learning Research, 15:1111–1133, 2014.
	- [Large-scale L-BFGS using MapReduce]() 该论文讲述了运用了hashing技术后，AUC的变化。

- [幻灯]《Hashing for Machine Learning》http://t.cn/RAZxF7Y 用于机器学习特征工程的哈希

### 特征选择

- [Selecting good features](http://blog.datadive.net/selecting-good-features-part-i-univariate-selection/) 特征工程系列文章：Part1. [单变量选取](http://t.cn/Rw4B2vO) Part2.[线性模型和正则化](http://t.cn/Rw4Blqc) Part3.[随机森林](http://t.cn/Rw4BEAQ) Part4.[稳定性选择法、递归特征排除法RFE及综合比较](http://t.cn/Rw4rndV) 内容很赞，还有Python代码示例。

- [关于推荐系统中的特征工程](http://phunters.lofter.com/post/86d56_194e956)

### 预估模型

竞价搜索广告中的点击率预估法: 特征和模型

- [经典LR WWW07](http://www2007.org/papers/paper784.pdf)，[L1正则版ICML07](http://t.cn/RZOSmEl)
- 高质量特征+组合LR和BDT [ADKDD14](http://t.cn/RZOSmET)
- 加LDA话题特征 [Peacock: Learning Long-Tail Topic Features for Industrial Applications](http://arxiv.org/pdf/1405.4402v3.pdf)
- 组合ANN和BDT [USING NEURAL NETWORKS FOR CLICK PREDICTION OF SPONSORED SEARCH](http://arxiv.org/pdf/1412.6601v1.pdf)

[Practical Lessons from Predicting Clicks on Ads at Facebook](http://quinonero.net/Publications/predicting-clicks-facebook.pdf)

- [利用GBDT模型构造新特征](https://breezedeus.github.io/2014/11/19/breezedeus-feature-mining-gbdt.html)
- 特征决定了所有算法效果的上限，而不同的算法只是离这个上限的距离不同而已。
- 这篇论文的思想：先用已有特征训练GBDT模型，然后利用GBDT模型学习到的树来构造新特征，最后把这些新特征加入原有特征一起训练模型。构造的新特征向量是取值0/1的，向量的每个元素对应于GBDT模型中树的叶子结点。当一个样本点通过某棵树最终落在这棵树的一个叶子结点上，那么在新特征向量中这个叶子结点对应的元素值为1，而这棵树的其他叶子结点对应的元素值为0。新特征向量的长度等于GBDT模型里所有树包含的叶子结点数之和。
- 已经有人利用这种方法赢得了Kaggle一个CTR预估比赛的冠军，[代码](https://github.com/guestwalk/kaggle-2014-criteo)，里面有这种方法的具体实现。

[Viewability Prediction for Online Display Ads by Wang,CIKM15](http://t.cn/RLDduXf) 由于用户没有一直往下滚动网页,导致网页上的展示广告有一半实际上并没有被用户看到; 因此广告的可见性预测问题会影响广告推送、实时竞价和推荐系统. 利用概率隐藏类模型预测<用户,网页>的最大滚动深度; 考虑七种特征。

### 在线学习

[在线学习算法FTRL详解](http://www.52ml.net/16256.html) [link2](http://www.cnblogs.com/EE-NovRain/p/3810737.html)

现在做在线学习和CTR常常会用到逻辑回归（ Logistic Regression），而传统的批量（batch）算法无法有效地处理超大规模的数据集和在线数据流，google先后三年时间（2010年-2013年）从理论研究到实际工程化实现的FTRL（Follow-the-regularized-Leader）算法，在处理诸如逻辑回归之类的带非光滑正则化项（例如1范数，做模型复杂度控制和稀疏化）的凸优化问题上性能非常出色。

损失函数 LogLoss (logistic loss)为：
$$l_t(w_t) = −y_t\log(p_t) − (1−y_t)log(1−p_t)$$
其中\\(x_t\\)是instance feature vector at round t。

其梯度为：
$$\nabla l_t(w) = (σ(w·x_t) − y_t)x_t = (p_t − y_t)x_t$$

一般而言，求解online问题通常用:OGD(online gradient descent)算法，OGS的梯度更新公式为：

$$w_{t+1} = w_t − η_t.g_t$$ 其中$$η_t=\frac{1}{\sqrt(t)}$$

OGD算法准确性较好，但稀疏性不强。所以为此提出一些改进方法，例如

- FOBOS [J. Duchi and Y. Singer. Efficient learning using forward-backward splitting]()
- truncated gradient 20 [J. Langford, L. Li, and T. Zhang. Sparse online learning via truncated gradient]()
- Regularized Dual Averaging (RDA) [L. Xiao. Dual averaging method for regularized stochastic learning and online optimization]()

结合OGD的准确性和RDA算法的稀疏性，从而得到"Follow The (Prox-imally) Regularized Leader"算法。

FTRL的梯度更新公式为：
![](https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/ftrl_gradient.png)

FTRL的完整算法为：
![](https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/ftrl_algorithm.png)

上面值得一提的是learning rate的设定，利用了per-coordinate方法。意思是对w的每一维分开训练更新的，每一维使用的是不同的学习速率，如下面公式所示：
![](https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/ftrl_per_coordinate.png)

与w所有特征维度使用统一的学习速率相比，这种方法考虑了训练样本本身在不同特征上分布的不均匀性，如果包含w某个维度特征的训练样本很少，每一个样本都很珍贵，那么该特征维度对应的训练速率可以独自保持比较大的值，每来一个包含该特征的样本，就可以在该样本的梯度上前进一大步，更快的对新样本数据做出响应。而如果包含w某个维度特征的训练样本很多，则训练速率可以下降得比较快。

除此，论文还提到几种节省存储的方法：

- 在线去除训练数据中很少出现的特征，两种方法：(1)以一定概率p接受新特征；(2)利用counting bloom filter，出现次数大约n次的特征才会加入模型。
- 浮点数利用q2.13编码(只需要16bit)而不是64-bit floating point。
- 同时训练若干相似model，方便feature和模型评估。
- single value struct。
- 使用正负样本的数目来近似计算梯度的和。
- 对负样本数据进行抽样，在训练时计算loss和gradient时，再用大于1的权重弥补负样本。

关于CALIBRATING PREDICTIONS

- 简单方法，矫正公式为: \\(\tau(p) = \gamma p^{\kappa}\\)，再利用Poisson regression学习参数γ和κ。
- piecewise linear or piecewise constant correction function，利用isotonic regression。参考文献:
[Classifier calibration with Platt's scaling and isotonic regression](http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/)
[A. Niculescu-Mizil and R. Caruana. Predicting good probabilities with supervised learning]()，
[R. Luss, S. Rosset, and M. Shahar. Efficient regularized isotonic regression with application to gene–gene interaction search]()

### 点击率预测的几个问题

[新广告问题：explore and exploit EE-想说爱你不容易](http://jhuangpku.github.io/ee-xiang-shuo-ai-ni-bu-rong-yi.html)

[AUC上升CTR一定上升么](http://jhuangpku.github.io/aucshang-sheng-ctryi-ding-shang-sheng-yao.html)

- 文中归纳了三个原因：环境特征的引入，点击率和relevance的偏差(点击率=true relevance * position_bias)，评估集合和线上集合的数据偏差（即survival-bias）；

[搜索广告点击率预测的几个有趣问题](http://1.guzili.sinaapp.com/?p=10)

- 如何建模广告之间的相互影响，广告和自然搜索结果的相互影响。广告的位置，广告的创意展现形式(静态or动态)，广告与自然搜索结果同时展现，这些都有影响。

- 如何保证新策略能长期有效？训练样本的变化则是我们自身策略无法保 持长期优秀的一个重要因素。新策略上线后，基于受影响后的样本重新训练模型效果就不一定像第一次那么稳定。

- 如何做好个性化？技术方面：个性化feature稀疏，训练模型困难；如何识别个体。产品方面：如何面向广告主解释个性化因素；系统异常排查困难。

- 如何做好相关性和预测点击率在排序中影响？这个点上，有很多经验证明，相关性与点击率没有很正向的关系。怎么做呢？相关性在触发阶段保证，排序阶段只考虑预测点击率，不失为一种方法。

- 如何做到广告系统更新时的平稳过渡？整体上来讲，每次策略变化都不会有突变，但反映到局部广告主上，哪怕是很小的策略更新，都可能对其造成翻天覆地的变化。

### Exploration and Exploitation

- [Bandit:一种简单而强大的在线学习算法](http://blog.findshine.com/2015/01/03/bandit.html)
- [新广告选择策略 meteorli,nelsonliao]()
- [Google Analytics 参考书目（多手柄老虎机）](https://support.google.com/analytics/answer/2847946?hl=zh-Hans&ref_topic=1745207)
- [Thompson sampling](http://en.wikipedia.org/wiki/Thompson_sampling)，[Analysis of Thompson Sampling for the Multi-armed Band](http://jmlr.org/proceedings/papers/v23/agrawal12/agrawal12.pdf)

### 其他方面

**[并行逻辑回归](http://blog.sina.com.cn/s/blog_6cb8e53d0101oetv.html)**

[csdn链接](http://www.csdn.net/article/1970-01-01/2818400)

这里的并行实现我已经也做过，赶明儿可以把代码拿出来再看一看。归纳如下：

- 棋盘式划分，从数据和feature两个维度做划分。
- 并行LR实际上就是在求解损失函数最优解的过程中，针对寻找损失函数下降方向中的梯度方向计算作了并行化处理，而在利用梯度确定下降方向的过程中也可以采用并行化。
- 先在各自单元上做计算，然后做行归并，相当于得到点积和，再把点积和分发到同一行的机器上，再各自计算，最后做列归并，得到下降方向。

**[广告数据上的大规模机器学习 夏粉](http://www.infoq.com/cn/presentations/large-scale-machine-learning-of-advertisement-data)**

- 以广告点击率预估问题为例，介绍如何利用大规模机器学习技术搭建一个容纳万亿特征数据的、分钟级别模型更新的、自动高效深度学习。
- 主要内容包括：数据采样，对负样本以r(0,1]采样，训练时，给予抽样的负样本权重为1/r；噪音检测，计算点击率随时间变化趋势 –百度首创:SA算法；特征删减，google的做法是新特征按概率p加入 Bloom Filter+次数超过n，百度是Fea-G算法；模型的时效性，从小时减少到分钟，CTR大幅提升；训练算法优化，Shooting算法；


**[Display Advertising Challenge](https://www.kaggle.com/c/criteo-display-ad-challenge)**

由[Criteo](http://www.criteo.com/cn/)发起的移动展示广告点击率预估的竞赛。

- Criteo自家的论文[Simple and scalable response prediction for display advertising](http://people.csail.mit.edu/romer/papers/TISTRespPredAds.pdf)
- [FTRL算法 benchemark实现](https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10322/beat-the-benchmark-with-less-then-200mb-of-memory) 参考Google的论文[Ad Click Prediction: a View from the Trenches](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf)
- NTU关于Criteo CTR Challenge的[winning solution](https://github.com/guestwalk/kaggle-2014-criteo)，有代码有slide。解决方案是用GBDT学intermediate feature，再配合raw feature，用FM训练CTR模型。其中GBDT学特征是参考了[Facebook ADKDD2014文章](http://quinonero.net/Publications/predicting-clicks-facebook.pdf)
- NTU他们对预测的CTR进行了一个calibration，使得其与true clicked likelihood/average estimated CTR更接近，如果最后evaluation metric是logloss，这有时会有较大改进。FastML上面介绍这个 [Platt's Scaling (SVM输出概率的方法) and Isotonic Regression](http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/)。@范涛_中科大。logloss参考下facebook的论文。

- NTU他们的方法，总结如下：

	- 预处理A：从原始数据中获取39类特征。
	- GBDT：30 trees with depth 7。GBDT处理后，输出特征类为30个，特征空间大小为30*2^7；
	- 预处理B：Hashing Trick，hashed into 1M-dimension
	- FFM：参考论文[Ensemble of Collaborative Filtering and Feature Engineered Models for Click Through Rate Prediction](https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf)
	- Calibration：Isotonic Regression

- 关于FM和CTR的其他论文，[papers](https://www.kaggle.com/about/papers)。下面这几篇是kdd2012的：

	- [Combining Factorization Model and Additive Forest for Collaborative Followee Recommendation]()
	- [Social Network and Click-through Prediction with Factorization Machines](https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Rendle.pdf)
	- [Scorecard with Latent Factor Models for User Follow Prediction Problem]()
	- [Context-aware Ensemble of Multifaceted Factorization Models for Recommendation Prediction in Social Networks]()
	- [Click-Through Prediction for Sponsored Search Advertising with Hybrid Models](https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/CAS.pdf)
	- [A Two-Stage Ensemble of Diverse Models for Advertisement Ranking in KDD Cup 2012]()

### 模型评估

- Evaluation。Precision, Recall, AUCs and ROCs 准确率、召回率、AUC(曲线下面积)和ROC(受试者工作特征曲线)，文中就很多Kaggle竞赛分类任务最终多个评判标准间的关系进行了讨论 [Precision, Recall, AUCs and ROCs](https://shapeofdata.wordpress.com/2015/01/05/precision-recall-aucs-and-rocs/)

## 其他资料

- [Sibyl: 来自Google的大规模机器学习系统] 在上周的IEEE/IFIP可靠系统和网络（DSN）国际会议上，Google软件工程师Tushar Chandra做了一个关于Sibyl系统的主题演讲。 Sibyl是一个监督式机器学习系统，用来解决预测方面的问题，比如YouTube的视频推荐。[PDF](https://users.soe.ucsc.edu/~niejiazhong/slides/chandra.pdf)，[page](http://www.infoq.com/cn/news/2014/07/google-sibyl)

- [汤兴-爱奇艺大脑—视频进化](http://weibo.com/p/1001603803645836675771)

- 在线实验效果检验
	- [PlanOut facebook实验框架](http://facebook.github.io/planout/docs/about-planout.html)

- [课程-刘鹏-计算广告学](http://study.163.com/course/introduction/321007.htm)


